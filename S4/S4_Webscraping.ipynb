{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-Scraping. Семинар"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас есть код, который собирает ссылки на страницы всех преподавателей, которые ведут у второго курса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Не удалось получить ссылку\n",
      "Не удалось получить ссылку\n",
      "Не удалось получить ссылку\n",
      "Не удалось получить ссылку\n",
      "Не удалось получить ссылку\n",
      "Не удалось получить ссылку\n",
      "Не удалось получить ссылку\n",
      "Не удалось получить ссылку\n",
      "Не удалось получить ссылку\n",
      "Не удалось получить ссылку\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "link = 'https://www.hse.ru/ba/we/tutors' \n",
    "page = requests.get(link) \n",
    "\n",
    "soup = BeautifulSoup(page.text) \n",
    "\n",
    "links = set() \n",
    "\n",
    "for person in soup.find_all('div', {'class':\"b-greetings__item b-greetings__tutor\"}):\n",
    "    course_info = person.find('div', {'class':\"b-greetings__descr small\"})\n",
    "    if '2-й курс' in course_info.get_text():\n",
    "        try:\n",
    "            person_info = person.find('div', {'class':\"b-greetings__person_data small\"})\n",
    "            links.add('https://www.hse.ru' + person_info.find('a').get('href'))\n",
    "        except:\n",
    "            print('Не удалось получить ссылку')\n",
    "    \n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что у нас нет ссылок, которые ведут не на личную страничку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://www.hse.ru/best'}\n"
     ]
    }
   ],
   "source": [
    "to_remove = set()\n",
    "\n",
    "for link in links:\n",
    "    if 'persons' not in link: # если в ссылке нет подстроки `persons`, то добавь ее в множество кандидатов на удаление\n",
    "        to_remove.add(link)\n",
    "\n",
    "print(to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим странички через разность множеств."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links - to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы ускорить процесс, будем скачиывать файлы и считать статистику для первых 10 преподавателей, а потом можем запустить код для всех."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.hse.ru/mirror/org/persons/redir/101530936?pl=', 'https://www.hse.ru/mirror/org/persons/redir/101534274?pl=', 'https://www.hse.ru/mirror/org/persons/redir/101539618?pl=', 'https://www.hse.ru/mirror/org/persons/redir/101555405?pl=', 'https://www.hse.ru/mirror/org/persons/redir/102646386?pl=', 'https://www.hse.ru/mirror/org/persons/redir/10443162?pl=', 'https://www.hse.ru/mirror/org/persons/redir/10444528?pl=', 'https://www.hse.ru/mirror/org/persons/redir/10445847?pl=', 'https://www.hse.ru/mirror/org/persons/redir/105131657?pl=', 'https://www.hse.ru/mirror/org/persons/redir/105604470?pl=']\n"
     ]
    }
   ],
   "source": [
    "first_ten = sorted(links)[:10] # отсортируем, чтобы работать с одинаковыми страничками\n",
    "print(first_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем скачать резюме для какого-нибудь преподавателя из нашего списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(first_ten[1]).text\n",
    "print('Резюме' in page) # проверяем, есть ли на странице ссылка на резюме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"link\" href=\"/data/2019/10/30/391720357032193/CV.pdf\" target=\"_blank\">Резюме</a>]\n",
      "/data/2019/10/30/391720357032193/CV.pdf\n",
      "Хажгериева Анастасия Игоревна\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ссылка на резюме есть, поэтому продолжим обработку страницы\n",
    "soup_link = BeautifulSoup(page)\n",
    "\n",
    "# находим нужную ссылку по тексту\n",
    "print(soup_link.find_all('a', text='Резюме')) \n",
    "\n",
    "# достаем сам адрес ссылки на резюме\n",
    "print(soup_link.find_all('a', text='Резюме')[0].get('href')) \n",
    "\n",
    "# восстанавливаем полный адрес ссылки на резюме\n",
    "cv_link = 'https://www.hse.ru' + soup_link.find_all('a', text='Резюме')[0].get('href')\n",
    "\n",
    "# достаем имя сотрудника для того, чтобы назвать файл\n",
    "name = soup_link.find('h1').get_text()\n",
    "print(name)\n",
    "\n",
    "# обращаемся по ссылке к файлу\n",
    "doc = requests.get(cv_link)\n",
    "\n",
    "# проверяем расширение файла, который хранится по ссылке\n",
    "print(doc.headers['Content-Type'].split('/')[1] == 'pdf')\n",
    "\n",
    "\n",
    "# создаем файл в режиме записи бинарной информации\n",
    "with open(f'{name}.pdf', 'wb') as fh:\n",
    "    # записываем в файл содержание файла по ссылке в байтах\n",
    "    fh.write(doc.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте напишем функцию и применим ее ко всем ссылкам в нашем списке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CV(link):\n",
    "    page = requests.get(link).text\n",
    "    if 'Резюме' in page:\n",
    "        soup_link = BeautifulSoup(page, 'lxml')\n",
    "        cv_link = 'https://www.hse.ru' + soup_link.find_all('a', text='Резюме')[0].get('href')\n",
    "        doc = requests.get(cv_link)\n",
    "        if doc.headers['Content-Type'].split('/')[1] == 'pdf':\n",
    "            name = soup_link.find('h1').get_text()\n",
    "            with open(f'{name}.pdf', 'wb') as fh:\n",
    "                fh.write(doc.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in first_ten:\n",
    "    get_CV(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Самостоятельное задание: \n",
    "На странице сотрудников есть информация о владении иностранными языками. Для сотрудников факультета создайте словарь, где ключом будет язык, а значением - количество сотрудников, которые указали, что владеют им. Выведите ключи и значения словаря, отсортированные по значениям от большего к меньшему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('английский', 8), ('испанский', 2), ('итальянский', 1), ('немецкий', 2), ('русский', 1), ('украинский', 1), ('французский', 2), ('шведский', 1)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random \n",
    "\n",
    "lang_dict = {}\n",
    "cnt = 0\n",
    "\n",
    "for link in first_ten:\n",
    "    try:\n",
    "        time.sleep(random.randint(1,5))\n",
    "        page = requests.get(link).text\n",
    "        soup_link = BeautifulSoup(page, 'lxml')\n",
    "        lang = soup_link.find_all('dl', {'class':\"main-list large main-list-language-knowledge-level\"})[0]\n",
    "        for l in lang.find_all('dd'):\n",
    "            l_text = l.get_text()\n",
    "            lang_dict[l_text] = lang_dict.get(l_text, 0) + 1\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(sorted(lang_dict.items(), key = lambda x: x[0]), end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь запустим для всех. Внимание, этот код может легко выполняться 5-15 минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываю ссылку №50 из 198\n",
      "Обрабатываю ссылку №100 из 198\n",
      "Обрабатываю ссылку №150 из 198\n",
      "[('английский', 146), ('английский (Преподаю английский)', 1), ('английский (продвинутый уровень)', 1), ('английский (профессиональное владение)', 1), ('английский (свободное владение/C2)', 1), ('арабский', 2), ('древнеанглийский', 1), ('древнегреческий', 1), ('древнеегипетский', 1), ('иврит', 2), ('испанский', 21), ('итальянский', 10), ('итальянский (CILS C1)', 1), ('китайский', 5), ('латинский', 3), ('литовский', 1), ('немецкий', 59), ('немецкий (Изучала немецкий в университете)', 1), ('немецкий (средний/A2.2)', 1), ('польский', 4), ('португальский', 4), ('румынский', 1), ('румынский (молдавский)', 1), ('русский', 6), ('русский (профессиональный преподаватель РКИ)', 1), ('русский (родной язык)', 1), ('сербский', 1), ('узбекский', 1), ('украинский', 2), ('финский', 1), ('французский', 41), ('французский (начальный/A2.1)', 1), ('французский (средний уровень)', 1), ('хорватский', 1), ('шведский', 1), ('японский', 4), ('японский (начальный/A2.1)', 1)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random \n",
    "\n",
    "lang_dict = {}\n",
    "cnt = 0\n",
    "\n",
    "for link in links: # проходим по множеству всех наших преподавателей\n",
    "    cnt += 1\n",
    "    if cnt % 10 == 0:\n",
    "        print(f'Обрабатываю ссылку №{cnt} из {len(links)}') # добавим счетчик, чтобы у нас печатался своеобразный progress bar\n",
    "    try:\n",
    "        time.sleep(random.randint(1,5))\n",
    "        page = requests.get(link).text\n",
    "        soup_link = BeautifulSoup(page, 'lxml')\n",
    "        lang = soup_link.find_all('dl', {'class':\"main-list large main-list-language-knowledge-level\"})[0]\n",
    "        for l in lang.find_all('dd'):\n",
    "            l_text = l.get_text()\n",
    "            lang_dict[l_text] = lang_dict.get(l_text, 0) + 1\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(sorted(lang_dict.items(), key = lambda x: x[0]), end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим пунктом будет решить проблему, как избавиться от уточнений вида `(продвинутый уровень)` и так далее."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
